# -*- coding: utf-8 -*-
import streamlit as st
import google.generativeai as genai
import json
import os

# --- C·∫•u h√¨nh ·ª©ng d·ª•ng ---
st.set_page_config(page_title="INNO HR Chatbot", page_icon="ü§ñ")
st.title("ü§ñ Beta App H·ªèi ƒê√°p Nh√¢n S·ª± INNO")
st.caption("H·ªèi ƒë√°p d·ª±a tr√™n d·ªØ li·ªáu n·ªôi b·ªô (JSON)")

# --- T·∫£i d·ªØ li·ªáu nh√¢n s·ª± t·ª´ file JSON ---
JSON_FILE_PATH = "data.json"

@st.cache_data
def load_knowledge(file_path):
    """T·∫£i d·ªØ li·ªáu JSON m√† kh√¥ng chi·∫øm qu√° nhi·ªÅu b·ªô nh·ªõ"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)  # Tr·∫£ v·ªÅ object JSON thay v√¨ string
    except FileNotFoundError:
        st.sidebar.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file '{file_path}'!")
        return None
    except json.JSONDecodeError:
        st.sidebar.error(f"‚ùå File '{file_path}' kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON!")
        return None
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return None

knowledge_text = load_knowledge(JSON_FILE_PATH)

if knowledge_text is None:
    st.error("Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông ·ª©ng d·ª•ng do l·ªói nghi√™m tr·ªçng khi t·∫£i d·ªØ li·ªáu ki·∫øn th·ª©c. Vui l√≤ng ki·ªÉm tra file data.json v√† th·ª≠ l·∫°i.")
    st.stop()
else:
     st.sidebar.success(f"ƒê√£ t·∫£i th√†nh c√¥ng d·ªØ li·ªáu t·ª´ {JSON_FILE_PATH}")

# 2. C·∫•u h√¨nh Google Generative AI
api_key = os.getenv("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY", None)

if not api_key:
    st.error("L·ªói: API Key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY ho·∫∑c c·∫•u h√¨nh GOOGLE_API_KEY trong Streamlit Secrets.")
    st.stop()

try:
    genai.configure(api_key=api_key)
except Exception as e:
     st.error(f"L·ªói khi c·∫•u h√¨nh Google AI v·ªõi API Key: {e}")
     st.stop()

MODEL_NAME = "gemini-2.5-pro-exp-03-25" # Ho·∫∑c 'gemini-pro' n·∫øu c·∫ßn
try:
    # Th√™m c√†i ƒë·∫∑t an to√†n ƒë·ªÉ ch·∫∑n n·ªôi dung kh√¥ng ph√π h·ª£p n·∫øu c·∫ßn
    # safety_settings = [
    #     {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    #     {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    #     {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    #     {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    # ]
    model = genai.GenerativeModel(
        MODEL_NAME
        # , safety_settings=safety_settings # B·ªè comment n·∫øu d√πng safety_settings
        )
    st.sidebar.info(f"S·ª≠ d·ª•ng model: {MODEL_NAME}")
except Exception as e:
    st.error(f"L·ªói khi kh·ªüi t·∫°o model '{MODEL_NAME}': {e}. C√≥ th·ªÉ model kh√¥ng t·ªìn t·∫°i ho·∫∑c API key kh√¥ng h·ª£p l·ªá/kh√¥ng c√≥ quy·ªÅn truy c·∫≠p.")
    st.stop()

# --- System Prompt ---
system_instruction_text = """
B·∫°n l√† tr·ª£ l√Ω nh√¢n s·ª± c·ªßa c√¥ng ty INNO. B·∫°n ch·ªâ ƒë∆∞·ª£c s·ª≠ d·ª•ng d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.
N·∫øu th√¥ng tin kh√¥ng c√≥ trong d·ªØ li·ªáu, h√£y tr·∫£ l·ªùi: "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin trong d·ªØ li·ªáu c√≥ s·∫µn."
ƒê·ª´ng ƒë∆∞a ra suy ƒëo√°n ho·∫∑c th√¥ng tin kh√¥ng ch·∫Øc ch·∫Øn.
"""

# C·∫•u h√¨nh t·∫°o n·ªôi dung
generation_config = genai.types.GenerationConfig(
    response_mime_type="text/plain",
    temperature=0.7 # Gi·ªØ nguy√™n nhi·ªát ƒë·ªô
)

# --- THAY ƒê·ªîI QUAN TR·ªåNG: H√†m Helper ƒë·ªÉ x·ª≠ l√Ω Stream ---
def stream_text_generator(stream):
    """
    H√†m n√†y nh·∫≠n stream t·ª´ API, l·∫∑p qua c√°c chunk,
    v√† ch·ªâ yield ph·∫ßn text c·ªßa m·ªói chunk.
    """
    for chunk in stream:
        # Ki·ªÉm tra xem chunk c√≥ d·ªØ li·ªáu text kh√¥ng tr∆∞·ªõc khi yield
        # M·ªôt s·ªë chunk ban ƒë·∫ßu ho·∫∑c cu·ªëi c√πng c√≥ th·ªÉ kh√¥ng c√≥ 'text'
        if hasattr(chunk, 'text') and chunk.text:
             yield chunk.text
        # C√≥ th·ªÉ th√™m x·ª≠ l√Ω cho c√°c ph·∫ßn kh√°c c·ªßa chunk n·∫øu c·∫ßn (v√≠ d·ª•: l·ªói, safety ratings)

# --- Ph·∫ßn Giao di·ªán v√† X·ª≠ l√Ω ---

# --- Giao di·ªán nh·∫≠p c√¢u h·ªèi ---
st.write("üí° Nh·∫≠p c√¢u h·ªèi v√†o √¥ b√™n d∆∞·ªõi v√† nh·∫•n Enter ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin nh√¢n s·ª±.")
user_question = st.text_input(
    "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:",
    key="user_question",
    placeholder="V√≠ d·ª•: Cho t√¥i bi·∫øt email c·ªßa √¥ng ƒêo√†n VƒÉn ƒê·ªông?"
)

response_placeholder = st.container()

if user_question:
    if knowledge_text:
        full_prompt = f"{system_instruction_text}\n\nD∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu nh√¢n s·ª± d·∫°ng JSON:\n```json\n{knowledge_text}\n```\n\nD·ª±a v√†o d·ªØ li·ªáu tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi sau:\n\"{user_question}\""
        contents = [full_prompt]

        try:
            response_placeholder.empty()
            with response_placeholder:
                 with st.spinner(f"ƒêang t√¨m ki·∫øm c√¢u tr·∫£ l·ªùi v·ªõi {MODEL_NAME}..."):
                    response_stream = model.generate_content(
                        contents,
                        stream=True,
                        generation_config=generation_config
                    )

                    st.markdown("**C√¢u tr·∫£ l·ªùi:**")
                    # --- THAY ƒê·ªîI QUAN TR·ªåNG: S·ª≠ d·ª•ng h√†m helper ---
                    # Truy·ªÅn stream g·ªëc v√†o h√†m helper,
                    # v√† truy·ªÅn k·∫øt qu·∫£ c·ªßa h√†m helper (ch·ªâ ch·ª©a text) v√†o st.write_stream
                    st.write_stream(stream_text_generator(response_stream))

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói khi g·ªçi Gemini API: {e}")
            print(f"Error calling Gemini API: {e}")
    else:
         st.error("L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu ki·∫øn th·ª©c ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi.")

elif not user_question: # Ch·ªâ hi·ªÉn th·ªã khi √¥ tr·ªëng v√† kh√¥ng c√≥ l·ªói g√¨ kh√°c
    pass # Placeholder ƒë√£ hi·ªÉn th·ªã th√¥ng b√°o m·∫∑c ƒë·ªãnh

st.sidebar.markdown("---")
st.sidebar.caption("¬© 2025 - Beta App v0.3")